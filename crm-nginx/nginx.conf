worker_processes auto;

events {
    worker_connections 4096;  # Increase from 1024 to handle more concurrent connections
    use epoll;  # Use 'epoll' for Linux to handle many connections efficiently
    multi_accept on;  # Accept multiple connections at a time
}

http {
    include       mime.types;
    default_type  application/octet-stream;

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=my_cache:10m max_size=1g inactive=60m use_temp_path=off;
    proxy_buffering on;  # Enable proxy buffering for performance
    proxy_buffers 16 4k;  # Adjust buffer size for response data
    proxy_buffer_size 8k;

    # Set timeout settings to prevent long waiting times
    proxy_connect_timeout 30s;  # Timeout for establishing a connection to the backend
    proxy_read_timeout 60s;     # Timeout for reading a response from the backend
    proxy_send_timeout 60s;     # Timeout for sending a request to the backend
    proxy_http_version 1.1;
    proxy_set_header Connection "";  # Enable keep-alive for upstream servers

    keepalive_timeout 65;
    keepalive_requests 1000;  # Allow Nginx to keep 1000 requests alive before closing

    sendfile        on;

    gzip on;
    gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;
    gzip_min_length 1000;  # Compress only responses larger than 1000 bytes
    gzip_comp_level 5;  # Compression level (1 to 9, where 9 is the maximum compression)
    gzip_vary on;  # Add 'Vary: Accept-Encoding' header to responses

    client_max_body_size 10M;  # Limit request body size to 10MB

    limit_req_zone $binary_remote_addr zone=one:10m rate=30r/s;  # Allow 30 requests per second per IP
    limit_conn_zone $binary_remote_addr zone=addr:10m;  # Limit the number of connections per IP

    server {
        listen 443 ssl;  # SSL on port 443
        http2  on; # Enable HTTP/2
        server_name localhost;
        ssl_certificate /etc/nginx/ssl/nginx.crt;  # Add SSL certificates for HTTPS
        ssl_certificate_key /etc/nginx/ssl/nginx.key;
        limit_req zone=one burst=10;  # Allow bursts of up to 10 requests
        limit_conn addr 20;  # Limit to 20 concurrent connections per IP

       # Forward to localhost:8081
        location / {
                   proxy_pass http://host.docker.internal:8081/;
                   proxy_set_header Host $host;
                   proxy_set_header X-Real-IP $remote_addr;
                   proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                   proxy_set_header X-Forwarded-Proto $scheme;
                   proxy_set_header X-Forwarded-From-Nginx true; # Add custom header
                   proxy_cache my_cache;
                   proxy_cache_valid 200 1h;  # Cache responses with HTTP 200 for 1 hour
                   proxy_cache_valid 404 1m;  # Cache 404 errors for 1 minute
                   add_header X-Cache-Status $upstream_cache_status;  # Add header to show cache status
                   proxy_cache_bypass $http_cache_control;  # Bypass cache on cache-control headers
               }

               # Forward Swagger API docs for staging-gr
               location /v3/api-docs/ {
                   proxy_pass http://host.docker.internal:8081/v3/api-docs/;
                   proxy_set_header Host $host;
                   proxy_set_header X-Real-IP $remote_addr;
                   proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                   proxy_set_header X-Forwarded-Proto $scheme;
                   proxy_set_header X-Forwarded-From-Nginx true; # Add custom header
                   proxy_cache my_cache;
                   proxy_cache_valid 200 1h;  # Cache responses with HTTP 200 for 1 hour
                   proxy_cache_valid 404 1m;  # Cache 404 errors for 1 minute
                   add_header X-Cache-Status $upstream_cache_status;  # Add header to show cache status
                   proxy_cache_bypass $http_cache_control;  # Bypass cache on cache-control headers
               }
        }
    }